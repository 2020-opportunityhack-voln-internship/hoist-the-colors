{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Waw4M3na3AmO","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uguFM1QO0PU4","colab_type":"code","colab":{}},"source":["import os\n","os.listdir('.')\n","os.getcwd()\n","os.chdir('/content/drive/My Drive/Colab Notebooks')\n","os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jt1cvmDaZAVn","colab_type":"code","colab":{}},"source":["pip install tensorflow_gpu==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui21Mu6QhZcP","colab_type":"code","colab":{}},"source":["pip install keras==2.4.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUJlQJCWY9Lg","colab_type":"code","colab":{}},"source":["pip install tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KreJkrkPiEB9","colab_type":"code","colab":{}},"source":["pip show tensorflow\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-sQWkCkWZ-j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595916376553,"user_tz":420,"elapsed":370,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}},"outputId":"c5a7fe04-8b02-4f26-c2b8-3aeb8cec50b3"},"source":["import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","# from nltk.stem import SnowballStemmer\n","from textblob import TextBlob\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","from keras.layers import Dense, Input, Embedding, Lambda, Dropout, SpatialDropout1D, GlobalAveragePooling1D, merge, Flatten, Bidirectional, GRU, GlobalMaxPooling1D\n","from keras.layers.merge import concatenate\n","from keras.models import Model\n","from keras import optimizers\n","from keras import initializers\n","from keras.engine import InputSpec, Layer\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import roc_auc_score\n","from sklearn.externals import joblib\n","from sklearn.model_selection import KFold"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8I2TswM23XWl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595915844266,"user_tz":420,"elapsed":1863,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["glove_embedding_file = '/content/drive/My Drive/Colab Notebooks/glove.840B.300d.txt'\n","train_data_file = '/content/drive/My Drive/Colab Notebooks/train.csv'\n","test_data_file = '/content/drive/My Drive/Colab Notebooks/test.csv'\n","\n","max_sequence_length = 400\n","max_nb_words = 100000\n","embedding_size = 300\n","\n","train_data = pd.read_csv(train_data_file)\n","test_data = pd.read_csv(test_data_file)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f1tUEUPW4dgq","colab_type":"text"},"source":["# **Create embedding index**"]},{"cell_type":"code","metadata":{"id":"2_IVutHj3msb","colab_type":"code","colab":{}},"source":["def create_embedding_index(path):\n","    embeddings_index = {}\n","    with open(path, 'r', encoding='utf-8') as f:\n","      for line in f:\n","          words = line.split()\n","          try:\n","              word = words[0]\n","              values = np.asarray(words[1:], dtype='float32')\n","              embeddings_index[word] = values\n","          except:\n","              continue\n","\n","    return embeddings_index\n","\n","embeddings_index = create_embedding_index(glove_embedding_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwvCG8pK4xW-","colab_type":"text"},"source":["# **Clean data**"]},{"cell_type":"code","metadata":{"id":"ObledVIf4p8l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595915853137,"user_tz":420,"elapsed":370,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["def preprocess_text(text):\n","    # convert to lower case\n","    text = text.lower()\n","\n","    #remove links and numbers\n","    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n","    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n","\n","    #spelling check (Takes a really long time)\n","    # text = str(TextBlob(text).correct())\n","    \n","    #abbreviations \n","    text = re.sub(r\"what's\", \"what is \", text)\n","    text = re.sub(r\"\\'s\", \" \", text)\n","    text = re.sub(r\"\\'ve\", \" have \", text)\n","    text = re.sub(r\"can't\", \"cannot \", text)\n","    text = re.sub(r\"n't\", \" not \", text)\n","    text = re.sub(r\"i'm\", \"i am \", text)\n","    text = re.sub(r\"\\'re\", \" are \", text)\n","    text = re.sub(r\"\\'d\", \" would \", text)\n","    text = re.sub(r\"\\'ll\", \" will \", text)\n","    text = re.sub(r\",\", \" \", text)\n","    text = re.sub(r\"\\.\", \" \", text)\n","    text = re.sub(r\"!\", \" ! \", text)\n","    text = re.sub(r\"\\/\", \" \", text)\n","    text = re.sub(r\"\\?\", \" ? \", text)\n","    text = re.sub(r\"\\!\", \" ! \", text)\n","    text = re.sub(r\"\\\"\", \" \", text)\n","    text = re.sub(r\"\\^\", \" ^ \", text)\n","    text = re.sub(r\"\\+\", \" + \", text)\n","    text = re.sub(r\"\\-\", \" - \", text)\n","    text = re.sub(r\"\\=\", \" = \", text)\n","    text = re.sub(r\"'\", \" \", text)\n","    text = re.sub(r\":\", \" : \", text)\n","    text = re.sub(r\" e g \", \" eg \", text)\n","    text = re.sub(r\" b g \", \" bg \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    text = re.sub(r\" 9 11 \", \"911\", text)\n","    text = re.sub(r\"e - mail\", \"email\", text)\n","    text = re.sub(r\"j k\", \"jk\", text)\n","\n","    #remove special characters\n","    text = re.sub(r'[^?!.,:a-z\\d ]', '',text, flags=re.IGNORECASE)\n","    \n","    #stop word removal\n","    STOPWORDS = set(stopwords.words('english'))\n","    text = \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n","\n","    return text"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RXaRaZEW-uFn","colab_type":"text"},"source":["# **Process Text in dataset**"]},{"cell_type":"code","metadata":{"id":"o4ejfk4D9_ft","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595915896637,"user_tz":420,"elapsed":40579,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["train_sentences = train_data[\"comment_text\"].fillna(\"no comment\").values\n","test_sentences = test_data[\"comment_text\"].fillna(\"no comment\").values\n","classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","y = train_data[classes].values\n","\n","train_sentences = [preprocess_text(text) for text in train_sentences]    \n","test_sentences=[preprocess_text(text) for text in test_sentences]\n","\n","tokenizer = Tokenizer(num_words=max_nb_words, filters='\"#%&()+,-./:;<=>@[\\\\]^_`{|}~\\t\\n')\n","tokenizer.fit_on_texts(train_sentences + test_sentences)\n","\n","#save tokenizer\n","joblib_file = \"Tokenizer.pkl\"  \n","joblib.dump(tokenizer, joblib_file)\n","\n","train_sequences = tokenizer.texts_to_sequences(train_sentences)\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","\n","word_index = tokenizer.word_index\n","train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n","test_data = pad_sequences(test_sequences, maxlen=max_sequence_length)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj6eKdWX-_St","colab_type":"text"},"source":["## **Prepare embedding matrix**"]},{"cell_type":"code","metadata":{"id":"Zp-7_Dod_Cm0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595915945213,"user_tz":420,"elapsed":928,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["nb_words = len(word_index) + 1\n","embedding_matrix = np.zeros((nb_words, embedding_size))\n","\n","for word, i in word_index.items():\n","    if i >= max_nb_words:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XecFuls3_Lle","colab_type":"text"},"source":["# **Bidirectional Recurrent Neural Network**"]},{"cell_type":"code","metadata":{"id":"xoWFChQ3_OLM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595915948061,"user_tz":420,"elapsed":382,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["def rnn(nb_words, embedding_size, embedding_matrix, max_sequence_length, out_size):\n","    recurrent_units = 60\n","    input_layer = Input(shape=(max_sequence_length,))\n","    embedding_layer = Embedding(nb_words,\n","                                embedding_size,\n","                                weights=[embedding_matrix],\n","                                input_length=max_sequence_length,\n","                                trainable=False)(input_layer)\n","    embedding_layer = SpatialDropout1D(0.25)(embedding_layer)\n","\n","    #CuDNNGRU\n","    rnn_layer_1 = Bidirectional(GRU(recurrent_units, return_sequences=True))(embedding_layer)\n","    rnn_layer_2 = Bidirectional(GRU(recurrent_units, return_sequences=True))(rnn_layer_1)\n","    x = concatenate([rnn_layer_1, rnn_layer_2], axis=2)\n","\n","    last = Lambda(lambda t: t[:, -1], name='last')(x)\n","    maxpool = GlobalMaxPooling1D()(x)\n","    average = GlobalAveragePooling1D()(x)\n","\n","    concatenated_layer = concatenate([last, maxpool, average], axis=1)\n","    x = Dropout(0.5)(concatenated_layer)\n","    x = Dense(144, activation=\"relu\")(x)\n","    output_layer = Dense(out_size, activation=\"sigmoid\")(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    adam_optimizer = optimizers.Adam(lr=1e-3, decay=1e-6, clipvalue=5)\n","    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wclKJakA-G5","colab_type":"text"},"source":["# **Train Model**"]},{"cell_type":"code","metadata":{"id":"bLwGTa5uBCPK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595916731405,"user_tz":420,"elapsed":430,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}}},"source":["class RNNModel(object):\n","\n","    def __init__(self, model_stamp, epoch_num, learning_rate):\n","        self.models = []\n","        self.epoch_num = epoch_num\n","        self.learning_rate = learning_rate\n","        self.model_stamp = model_stamp\n","        self.val_loss = -1\n","        self.auc = -1\n","\n","    \n","    def train_k_folds(self, X, y, n_folds, batch_size, get_model_func):\n","        models = []\n","        fold_predictions = []\n","        score = 0\n","        total_auc = 0\n","\n","        #k-fold cross validation\n","        kf = KFold(n_splits=n_folds, random_state=None) \n","\n","        for fold_id, (train_index, val_index) in enumerate(kf.split(X)):\n","            print(\"Train:\", train_index, \"Validation:\",val_index)\n","            train_x, val_x = X[train_index], X[val_index] \n","            train_y, val_y = y[train_index], y[val_index]\n","\n","            model, bst_val_loss, fold_prediction, auc = self._train_model(\n","              get_model_func(), batch_size, train_x, train_y, val_x, val_y, fold_id)\n","            \n","            total_val_loss += bst_val_loss\n","            total_auc += auc\n","            models.append(model)\n","            fold_predictions.append(fold_prediction)\n","\n","        self.models = models\n","        self.val_loss = total_val_loss / n_folds\n","        self.auc = total_auc / n_folds\n","        return models, self.val_loss, self.auc, fold_predictions\n","\n","    def _train_model(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id):\n","        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2)\n","        model_path = self.model_stamp + str(fold_id) + '.h5'\n","        model_checkpoint = ModelCheckpoint(model_path, save_best_only=True, save_weights_only=True)\n","        hist = model.fit(train_x, train_y,\n","                         validation_data=(val_x, val_y),\n","                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n","                         callbacks=[early_stopping, model_checkpoint])\n","        best_val_score = min(hist.history['val_loss'])\n","        print(\"Validation score\", best_val_score)\n","        predictions = model.predict(val_x)\n","        auc = roc_auc_score(val_y, predictions)\n","        print(\"AUC Score\", auc)\n","        return model, best_val_score, predictions, auc"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9TI0bhqBIDS","colab_type":"code","colab":{}},"source":["def rnn_model():\n","    return rnn(nb_words, embedding_size, embedding_matrix, max_sequence_length, out_size=6)\n","\n","model = RNNModel(model_stamp='kmax_text_rnn', epoch_num=50, learning_rate=1e-3)\n","trained_models, val_loss, auc, fold_predictions = model.train_k_folds(train_data, y, n_folds=3, batch_size=256, get_model_func=rnn_model)\n","\n","print(\"Overall val-loss:\", val_loss, \"AUC\", auc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UjtAn1m2vBFi","colab_type":"text"},"source":["# **Save Model**"]},{"cell_type":"code","metadata":{"id":"LaNyNym7pubq","colab_type":"code","colab":{}},"source":["#choosing the best model\n","model = trained_models[1]\n","\n","#save model\n","model.save('RNN_Model.h5')\n","model = load_model('RNN_Model.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nKoiNNGgDmul","colab_type":"text"},"source":["# **Test Model**"]},{"cell_type":"code","metadata":{"id":"5B5Kanap4Ad3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595547453372,"user_tz":420,"elapsed":17986,"user":{"displayName":"Karishma Joseph","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKjBvkSwmhJalHEtYBS-DpZ3PtCyHQAkDlCa5QCA=s64","userId":"03647980348141807206"}},"outputId":"fa4c0833-226c-4b2d-d039-8a72af85e50b"},"source":["from sklearn.externals import joblib\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","import os\n","\n","CLASSES = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","test_sentences = [\"Go back to your country\"]\n","tokenizer = joblib.load('Tokenizer.pkl')\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","test_data = pad_sequences(test_sequences, maxlen=400)\n","model = load_model('RNN_Model.h5')\n","test_predicts = model.predict(test_data, batch_size=256, verbose=1)\n","print(test_predicts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 24ms/step\n","[[0.14269954 0.0015585  0.01939207 0.01231543 0.05094578 0.00594961]]\n"],"name":"stdout"}]}]}